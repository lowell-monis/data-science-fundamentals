{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter - Day 5 - Section 002\n",
    "## Lecture 5 - Assessing Coefficient Accuracy\n",
    "\n",
    "In the today's lectures, we are starting focused on simple linear regression, that is, fitting models of the form \n",
    "\n",
    "$$\n",
    "Y =  \\beta_0 +  \\beta_1 X_1 + \\varepsilon\n",
    "$$\n",
    "\n",
    "In this lab, we will use two different tools for linear regression. \n",
    "- [Scikit learn](https://scikit-learn.org/stable/index.html) is arguably the most used tool for machine learning in python \n",
    "- [Statsmodels](https://www.statsmodels.org) provides many of the statisitcial tests we've been learning in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, we start with our favorite standard imports. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing the Linear Regression we learned last time from sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating data \n",
    "Ok, let's run an example like was shown in class where we see the distribution of possible values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's code that decides on my function \n",
    "def myFunc(x, b0=2, b1=5): \n",
    "    return b0 + b1*x\n",
    "\n",
    "\n",
    "# Here's a command that generates 100 random data points from f(x) + epsilon\n",
    "def makeData(n = 100):\n",
    "    X = np.random.uniform(-2,2,n)\n",
    "    y = myFunc(X) + np.random.normal(size = n)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everytime you run this cell, you get slightly different data\n",
    "\n",
    "X,y = makeData()\n",
    "\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which means that every time you run this cell, you get a slightly different choice of coefficients\n",
    "# for the model learned\n",
    "\n",
    "X,y = makeData()\n",
    "X = X.reshape([len(X),1])\n",
    "y = y.reshape([len(y),1])\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n",
    "print( 'y = '+ str(round(reg.intercept_[0],4)) +' + ' + str(round(reg.coef_[0,0],4)) +  \" * x_1\"  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "If we assume that our data is coming from the setting \n",
    "\n",
    "$$\n",
    "Y = f(X) + \\varepsilon\n",
    "$$\n",
    "\n",
    "what is $\\mathrm{Var}(\\varepsilon)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now, lets just train our linear model lots of times, and collect the resulting coefficients\n",
    "\n",
    "beta0_list = []\n",
    "beta1_list = []\n",
    "for i in range(100):\n",
    "    X,y = makeData()\n",
    "    X = X.reshape([len(X),1])\n",
    "    y = y.reshape([len(y),1])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X,y)\n",
    "    beta1_list.append(reg.coef_[0,0])\n",
    "    beta0_list.append(reg.intercept_[0])\n",
    "\n",
    "print(beta1_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "Make a histogram of `beta1_list` and separately, `beta0_list`.  \n",
    "- What is the mean of each list. How does this compare to the acutal line we used to generate the data?\n",
    "- What is the standard deviation of each list? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance in estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's figure out the variance of the linear regression estimates. First off, we know that $\\sigma^2 = \\mathrm{Var}(\\varepsilon) = 1$, but let's pretend we didn't make up our own fake data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a single linear regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n",
    "print( 'y = '+ str(round(reg.intercept_[0],4)) +' + ' + str(round(reg.coef_[0,0],4)) +  \" * x_1\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can estimate $\\sigma$ using residual standard error:\n",
    "\n",
    "$$\n",
    "\\mathrm{RSE} = \\sqrt{\\mathrm{RSS}/(n-2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = reg.predict(X)\n",
    "residuals = y - predicted\n",
    "\n",
    "RSS = np.sum(residuals**2)\n",
    "RSE = np.sqrt(RSS/(len(y)-2))\n",
    "print(f\"RSE = {RSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the following code can compute the standard error of each coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're estimating sigma^2 by RSE^2\n",
    "sigma_sq = RSE**2\n",
    "\n",
    "# We have n = 100 data points\n",
    "n = 100\n",
    "\n",
    "# We can calculate the standard error of beta_0 and beta_1 using the formulas we learned in class\n",
    "x_bar = np.mean(X)\n",
    "denom = np.sum((X - x_bar)**2)\n",
    "beta0_var = sigma_sq * (1/n + x_bar**2/denom)\n",
    "SE_beta0 = np.sqrt(beta0_var)\n",
    "print(f\"Standard error of beta0: {SE_beta0}\")\n",
    "\n",
    "\n",
    "beta1_var = sigma_sq/denom\n",
    "SE_beta1 = np.sqrt(beta1_var)\n",
    "print(f\"Standard error of beta1: {SE_beta1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we had to work a bit to get this to write out the standard errors, we can use the `statsmodels` library instead of `sklearn` to get these values directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "mydata = pd.DataFrame({'X':X.flatten(), 'y':y.flatten()})\n",
    "linreg_smf = smf.ols('y ~ X', data = mydata).fit()\n",
    "# linreg_smf.summary()\n",
    "linreg_smf.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What is $SE(\\hat \\beta_0)$ and $SE(\\hat \\beta_1)$? Are they the same as what we calculated above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stop Icon](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Vienna_Convention_road_sign_B2a.svg/180px-Vienna_Convention_road_sign_B2a.svg.png)\n",
    "\n",
    "Great, you got to here! Hang out for a bit, there's more lecture before we go on to the next portion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 2. Assessing Coefficient Estimate Accuracy\n",
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `Diabetes` data set again, which you looked into from the last class. In case you've forgotten, there is information about the data set [in the documentation](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
    "diabetes_df['target'] = pd.Series(diabetes.target)\n",
    "\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Like last time, we're now going to fit to a simple linear regression to the models\n",
    "$$\n",
    "\\texttt{target} = \\beta_0 + \\beta_1 \\cdot\\texttt{s1}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\texttt{target} = \\beta_0 + \\beta_1 \\cdot\\texttt{s5}\n",
    "$$\n",
    "where the variables are \n",
    "- $\\texttt{s1}$: tc, total serum cholesterol\n",
    "\n",
    "- $\\texttt{s5}$: ltg, possibly log of serum triglycerides level. \n",
    "\n",
    "Let's start by looking at using `s5` to predict `target`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for completeness, here's our code to do linear regression from last time using `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# sklearn actually likes being handed numpy arrays more than \n",
    "# pandas dataframes, so we'll extract the bits we want and just pass it that. \n",
    "X = diabetes_df['s5'].values\n",
    "X = X.reshape([len(X),1])\n",
    "y = diabetes_df['target'].values\n",
    "y = y.reshape([len(y),1])\n",
    "\n",
    "# This code works by first creating an instance of \n",
    "# the linear regression class\n",
    "reg = LinearRegression()\n",
    "# Then we pass in the data we want it to use to fit.\n",
    "reg.fit(X,y)\n",
    "\n",
    "# and we can get the coefficients we want out of the model from the following code.\n",
    "\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "\n",
    "# I can do some fancy printing if I really want to\n",
    "lineString = str(round(reg.coef_[0,0],4)) +  \"x_1 + \" +  str(round(reg.intercept_[0],4))\n",
    "print( 'y = ', lineString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However today we're interested in statistical tests so we'll be using the `statsmodel` package. It has more options for statistical tests when available, however it has fewer models available which is why we will using a bit of both in this class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**<font color=red>Instructor note:</font>** There is a difference in here where the book uses \n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "model = sm.OLS(y, X)\n",
    "```\n",
    "which has some weird stuff with needing to include an intercept column and such. On homework problems and the like you can use this code or follow the book, either is acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the code is intentially written to look\n",
    "# more like R than like python, but it still works!\n",
    "# Double check..... the coefficients here should be\n",
    "# about the same as those found by scikit-learn\n",
    "est = smf.ols('target ~ s5', diabetes_df).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What is $SE(\\hat \\beta_0)$ and $SE(\\hat \\beta_1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** If we instead use `s1` to predict the target, are $SE(\\hat \\beta_0)$ and $SE(\\hat \\beta_1)$ higher or lower than what you found for the `s5` prediction? Is this reasonable? Try plotting your predictions against scatter plots of the data to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What are the confidence intervals for  $\\hat \\beta_1$ in the two cases (the prediction using `s1` and the prediction using `s5`)? Which is wider and why? \n",
    "\n",
    "*Hint: Check out the `est.conf_int` command or you can find this in the summary tables you've been using earlier.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What is the conclusion of the hypothesis test\n",
    "\n",
    "$$H_0: \\text{ There is no relationship between $X$ and $Y$}$$\n",
    "\n",
    "$$H_a: \\text{ There is some relationship between $X$ and $Y$}$$\n",
    "\n",
    "at a confidence level of $\\alpha = 0.05$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh hey look, there's another table with information stored by the statsmodel class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What is $R^2$ for the two models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Dr. Liz Munch, adapted by Dr. Mengsen Zhang, Michigan State University\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
